{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7bca243-ce3e-4bc6-801a-1497c23871a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.46.1-py3-none-any.whl (10.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Collecting huggingface-hub<1.0,>=0.23.2\n",
      "  Downloading huggingface_hub-0.26.2-py3-none-any.whl (447 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m447.5/447.5 kB\u001b[0m \u001b[31m44.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<0.21,>=0.20\n",
      "  Downloading tokenizers-0.20.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0mmm\n",
      "\u001b[?25hRequirement already satisfied: filelock in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Collecting regex!=2019.12.17\n",
      "  Downloading regex-2024.9.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (782 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m782.7/782.7 kB\u001b[0m \u001b[31m61.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from transformers) (24.1)\n",
      "Collecting tqdm>=4.27\n",
      "  Downloading tqdm-4.66.6-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting safetensors>=0.4.1\n",
      "  Downloading safetensors-0.4.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (435 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m435.0/435.0 kB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.9.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from requests->transformers) (3.4.0)\n",
      "Installing collected packages: tqdm, safetensors, regex, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed huggingface-hub-0.26.2 regex-2024.9.11 safetensors-0.4.5 tokenizers-0.20.1 tqdm-4.66.6 transformers-4.46.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07940d97-c4cf-445f-815a-1e6adff9304e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tf-keras\n",
      "  Using cached tf_keras-2.18.0-py3-none-any.whl (1.7 MB)\n",
      "Requirement already satisfied: tensorflow<2.19,>=2.18 in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from tf-keras) (2.18.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.67.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (0.37.1)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (24.3.25)\n",
      "Requirement already satisfied: six>=1.12.0 in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.16.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (18.1.1)\n",
      "Requirement already satisfied: keras>=3.5.0 in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (3.6.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.18.0)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (0.6.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.1.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (4.12.2)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.26.4)\n",
      "Requirement already satisfied: setuptools in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (63.2.0)\n",
      "Requirement already satisfied: packaging in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (24.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (0.4.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (4.25.5)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.6.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (3.4.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (3.12.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.5.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (0.2.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow<2.19,>=2.18->tf-keras) (0.44.0)\n",
      "Requirement already satisfied: optree in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (0.13.0)\n",
      "Requirement already satisfied: rich in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (13.9.2)\n",
      "Requirement already satisfied: namex in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (0.0.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (2024.8.30)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (2.2.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (3.10)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (3.0.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (3.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (3.0.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (0.1.2)\n",
      "Installing collected packages: tf-keras\n",
      "Successfully installed tf-keras-2.18.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f406e3e-28dc-499c-938d-7ab453de090d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Downloading datasets-3.1.0-py3-none-any.whl (480 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: packaging in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from datasets) (24.1)\n",
      "Requirement already satisfied: requests>=2.32.2 in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from datasets) (2.32.3)\n",
      "Collecting xxhash\n",
      "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting dill<0.3.9,>=0.3.0\n",
      "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting multiprocess<0.70.17\n",
      "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting aiohttp\n",
      "  Downloading aiohttp-3.10.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pandas\n",
      "  Downloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m55.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.23.0 in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from datasets) (0.26.2)\n",
      "Requirement already satisfied: fsspec[http]<=2024.9.0,>=2023.1.0 in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from datasets) (2024.9.0)\n",
      "Requirement already satisfied: filelock in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from datasets) (3.16.1)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from datasets) (4.66.6)\n",
      "Collecting pyarrow>=15.0.0\n",
      "  Downloading pyarrow-18.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (40.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.0/40.0 MB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from datasets) (1.26.4)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.5.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (241 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.9/241.9 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting async-timeout<5.0,>=4.0\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from aiohttp->datasets) (24.2.0)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.6/124.6 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting yarl<2.0,>=1.12.0\n",
      "  Downloading yarl-1.17.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.7/318.7 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting aiohappyeyeballs>=2.3.0\n",
      "  Downloading aiohappyeyeballs-2.4.3-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
      "Collecting tzdata>=2022.7\n",
      "  Downloading tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.6/346.6 kB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pytz>=2020.1\n",
      "  Using cached pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Collecting propcache>=0.2.0\n",
      "  Downloading propcache-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (208 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.9/208.9 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pytz, xxhash, tzdata, pyarrow, propcache, multidict, frozenlist, dill, async-timeout, aiohappyeyeballs, yarl, pandas, multiprocess, aiosignal, aiohttp, datasets\n",
      "Successfully installed aiohappyeyeballs-2.4.3 aiohttp-3.10.10 aiosignal-1.3.1 async-timeout-4.0.3 datasets-3.1.0 dill-0.3.8 frozenlist-1.5.0 multidict-6.1.0 multiprocess-0.70.16 pandas-2.2.3 propcache-0.2.0 pyarrow-18.0.0 pytz-2024.2 tzdata-2024.2 xxhash-3.5.0 yarl-1.17.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60031844-ee6c-4973-bd46-093a3790bb83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers[torch] in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (4.46.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from transformers[torch]) (2024.9.11)\n",
      "Requirement already satisfied: packaging>=20.0 in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from transformers[torch]) (24.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from transformers[torch]) (1.26.4)\n",
      "Requirement already satisfied: requests in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from transformers[torch]) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from transformers[torch]) (0.20.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from transformers[torch]) (4.66.6)\n",
      "Requirement already satisfied: filelock in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from transformers[torch]) (3.16.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from transformers[torch]) (6.0.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from transformers[torch]) (0.26.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from transformers[torch]) (0.4.5)\n",
      "Collecting accelerate>=0.26.0\n",
      "  Downloading accelerate-1.1.0-py3-none-any.whl (333 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m333.2/333.2 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torch in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from transformers[torch]) (2.5.0)\n",
      "Requirement already satisfied: psutil in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from accelerate>=0.26.0->transformers[torch]) (6.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers[torch]) (4.12.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers[torch]) (2024.9.0)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from torch->transformers[torch]) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from torch->transformers[torch]) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from torch->transformers[torch]) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from torch->transformers[torch]) (2.21.5)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from torch->transformers[torch]) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from torch->transformers[torch]) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from torch->transformers[torch]) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from torch->transformers[torch]) (12.3.1.170)\n",
      "Requirement already satisfied: triton==3.1.0 in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from torch->transformers[torch]) (3.1.0)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from torch->transformers[torch]) (12.4.127)\n",
      "Requirement already satisfied: networkx in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from torch->transformers[torch]) (3.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from torch->transformers[torch]) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from torch->transformers[torch]) (10.3.5.147)\n",
      "Requirement already satisfied: sympy==1.13.1 in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from torch->transformers[torch]) (1.13.1)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from torch->transformers[torch]) (11.6.1.9)\n",
      "Requirement already satisfied: jinja2 in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from torch->transformers[torch]) (3.1.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from sympy==1.13.1->torch->transformers[torch]) (1.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from requests->transformers[torch]) (2024.8.30)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from requests->transformers[torch]) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from requests->transformers[torch]) (2.2.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from requests->transformers[torch]) (3.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /mnt/netapp2/Store_uni/home/ulc/cursos/curso361/mypython/lib/python3.10/site-packages (from jinja2->torch->transformers[torch]) (3.0.1)\n",
      "Installing collected packages: accelerate\n",
      "Successfully installed accelerate-1.1.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d825cae-cd89-4a97-bce1-81c7c0ef8cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-16 21:35:59.052235: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-16 21:35:59.065403: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1734381359.081991 1956026 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1734381359.087022 1956026 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-16 21:35:59.104189: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: 2024-12-16 21:36:07.880877\n",
      "[1,   100] running_loss: 0.042\n",
      "[1,   200] running_loss: 0.031\n",
      "[1,   300] running_loss: 0.024\n",
      "[1,   400] running_loss: 0.023\n",
      "[1,   500] running_loss: 0.019\n",
      "[1,   600] running_loss: 0.026\n",
      "[1,   700] running_loss: 0.018\n",
      "[1,   800] running_loss: 0.022\n",
      "[1,   900] running_loss: 0.020\n",
      "[1,  1000] running_loss: 0.017\n",
      "[1,  1100] running_loss: 0.019\n",
      "[1,  1200] running_loss: 0.026\n",
      "[1,  1300] running_loss: 0.017\n",
      "[1,  1400] running_loss: 0.019\n",
      "[1,  1500] running_loss: 0.017\n",
      "[1,  1600] running_loss: 0.008\n",
      "[1,  1700] running_loss: 0.019\n",
      "[1,  1800] running_loss: 0.017\n",
      "[1,  1900] running_loss: 0.028\n",
      "[1,  2000] running_loss: 0.013\n",
      "[1,  2100] running_loss: 0.015\n",
      "[1,  2200] running_loss: 0.018\n",
      "[1,  2300] running_loss: 0.024\n",
      "[1,  2400] running_loss: 0.013\n",
      "[1,  2500] running_loss: 0.027\n",
      "[1,  2600] running_loss: 0.007\n",
      "[1,  2700] running_loss: 0.018\n",
      "[1,  2800] running_loss: 0.017\n",
      "[1,  2900] running_loss: 0.015\n",
      "[1,  3000] running_loss: 0.024\n",
      "[1,  3100] running_loss: 0.015\n",
      "[1,  3200] running_loss: 0.015\n",
      "[1,  3300] running_loss: 0.014\n",
      "[1,  3400] running_loss: 0.018\n",
      "[1,  3500] running_loss: 0.020\n",
      "[1,  3600] running_loss: 0.013\n",
      "[1,  3700] running_loss: 0.008\n",
      "[1,  3800] running_loss: 0.014\n",
      "[1,  3900] running_loss: 0.022\n",
      "[1,  4000] running_loss: 0.025\n",
      "[1,  4100] running_loss: 0.013\n",
      "[1,  4200] running_loss: 0.014\n",
      "[1,  4300] running_loss: 0.020\n",
      "[1,  4400] running_loss: 0.020\n",
      "[1,  4500] running_loss: 0.023\n",
      "[1,  4600] running_loss: 0.013\n",
      "[1,  4700] running_loss: 0.010\n",
      "[1,  4800] running_loss: 0.004\n",
      "[1,  4900] running_loss: 0.010\n",
      "[1,  5000] running_loss: 0.017\n",
      "[1,  5100] running_loss: 0.013\n",
      "[1,  5200] running_loss: 0.022\n",
      "[1,  5300] running_loss: 0.015\n",
      "[1,  5400] running_loss: 0.024\n",
      "[1,  5500] running_loss: 0.011\n",
      "[1,  5600] running_loss: 0.016\n",
      "[1,  5700] running_loss: 0.025\n",
      "[1,  5800] running_loss: 0.014\n",
      "[1,  5900] running_loss: 0.019\n",
      "[1,  6000] running_loss: 0.010\n",
      "[1,  6100] running_loss: 0.009\n",
      "[1,  6200] running_loss: 0.016\n",
      "[1,  6300] running_loss: 0.017\n",
      "[1,  6400] running_loss: 0.011\n",
      "[1,  6500] running_loss: 0.012\n",
      "[1,  6600] running_loss: 0.014\n",
      "[1,  6700] running_loss: 0.015\n",
      "[1,  6800] running_loss: 0.018\n",
      "[1,  6900] running_loss: 0.019\n",
      "[1,  7000] running_loss: 0.022\n",
      "[1,  7100] running_loss: 0.011\n",
      "[1,  7200] running_loss: 0.013\n",
      "[1,  7300] running_loss: 0.014\n",
      "[1,  7400] running_loss: 0.014\n",
      "[1,  7500] running_loss: 0.007\n",
      "[1,  7600] running_loss: 0.012\n",
      "[1,  7700] running_loss: 0.011\n",
      "[1,  7800] running_loss: 0.008\n",
      "[1,  7900] running_loss: 0.006\n",
      "[1,  8000] running_loss: 0.008\n",
      "[1,  8100] running_loss: 0.010\n",
      "[1,  8200] running_loss: 0.008\n",
      "[1,  8300] running_loss: 0.021\n",
      "[1,  8400] running_loss: 0.022\n",
      "[1,  8500] running_loss: 0.004\n",
      "[1,  8600] running_loss: 0.015\n",
      "[1,  8700] running_loss: 0.005\n",
      "[1,  8800] running_loss: 0.014\n",
      "[1,  8900] running_loss: 0.008\n",
      "[1,  9000] running_loss: 0.013\n",
      "[1,  9100] running_loss: 0.023\n",
      "[1,  9200] running_loss: 0.010\n",
      "[1,  9300] running_loss: 0.013\n",
      "[1,  9400] running_loss: 0.009\n",
      "[1,  9500] running_loss: 0.008\n",
      "[1,  9600] running_loss: 0.014\n",
      "[1,  9700] running_loss: 0.012\n",
      "[1,  9800] running_loss: 0.026\n",
      "[1,  9900] running_loss: 0.015\n",
      "[1, 10000] running_loss: 0.022\n",
      "[1, 10100] running_loss: 0.008\n",
      "[1, 10200] running_loss: 0.014\n",
      "[1, 10300] running_loss: 0.015\n",
      "[1, 10400] running_loss: 0.020\n",
      "[1, 10500] running_loss: 0.016\n",
      "[1, 10600] running_loss: 0.014\n",
      "[1, 10700] running_loss: 0.008\n",
      "[1, 10800] running_loss: 0.008\n",
      "[1, 10900] running_loss: 0.011\n",
      "Epoch 1/1, Loss: 1.5622186582014985\n",
      "End: 2024-12-16 23:17:28.605036\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertTokenizer, BertForQuestionAnswering\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import DataCollatorWithPadding\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "import datetime\n",
    "\n",
    "\n",
    "# Load the BERT model\n",
    "model = BertForQuestionAnswering.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Load tokenizer to prepare SQUAD data into BERT undesrtandable input\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\", use_fast=True)\n",
    "\n",
    "# Define a custom BERT model wrapper class like the ones in training.ipynb example\n",
    "class BertQA(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BertQA, self).__init__()\n",
    "        self.bert_qa = BertForQuestionAnswering.from_pretrained(model_name)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask, start_positions=None, end_positions=None):\n",
    "        outputs = self.bert_qa(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            start_positions=start_positions,\n",
    "            end_positions=end_positions\n",
    "        )\n",
    "        return outputs\n",
    "\n",
    "# Initialize the model\n",
    "model_name = \"bert-base-uncased\"\n",
    "model = BertQA()\n",
    "\n",
    "# Load SQUAD dataset\n",
    "dataset = load_dataset(\"squad\")\n",
    "\n",
    "# Function for data preprocessing: Turn SQUAD [context,question,answer] into BERT tokens\n",
    "def preprocess_data(examples):\n",
    "    questions = [q.strip() for q in examples[\"question\"]]\n",
    "    contexts = [c.strip() for c in examples[\"context\"]]\n",
    "\n",
    "    # Tokenize data for BERT\n",
    "    tokenized_examples = tokenizer(\n",
    "        questions,\n",
    "        contexts,\n",
    "        truncation=\"only_second\",          # If context is too long, truncate it\n",
    "        max_length=384,                    # Maximum length of token\n",
    "        stride=128,                        # Allows to reatin context of previous tokenization\n",
    "        return_overflowing_tokens=False,   # False for working with smaller datasets, True for better performance and working with bigger sets\n",
    "        return_offsets_mapping=True,       # Enable character index offsets\n",
    "        padding=\"max_length\"               # Add padding for uniform input size\n",
    "    )\n",
    "    \n",
    "    # Map answer positions to tokenized positions\n",
    "    offset_mapping = tokenized_examples.pop(\"offset_mapping\")\n",
    "    tokenized_examples[\"start_positions\"] = []\n",
    "    tokenized_examples[\"end_positions\"] = []\n",
    "\n",
    "    for i, offsets in enumerate(offset_mapping):\n",
    "        if len(examples[\"answers\"]) > i:                    # If there is an answer POSITION for the example\n",
    "            answer = examples[\"answers\"][i].get(\"text\", []) # Get the answer text\n",
    "            \n",
    "            if answer:  # If there is TEXT for the answer, find the tokens that correspond to the answer\n",
    "                answer = answer[0]\n",
    "                start_char = examples[\"answers\"][i].get(\"answer_start\", [0])[0]  # Get the answer's first character offset in the original context\n",
    "                end_char = start_char + len(answer)                              # Get the answer's last character offset \n",
    "                start_token = None\n",
    "                end_token = None\n",
    "\n",
    "                # Iterate the tokens to find which ones correspong to the answer\n",
    "                for j, (start, end) in enumerate(offsets):\n",
    "                    if start_char >= start and start_char < end:\n",
    "                        start_token = j\n",
    "                    if end_char > start and end_char <= end:\n",
    "                        end_token = j\n",
    "                        break\n",
    "                \n",
    "                if start_token is not None and end_token is not None:   # If the answer tokens were found, add them\n",
    "                    tokenized_examples[\"start_positions\"].append(start_token)\n",
    "                    tokenized_examples[\"end_positions\"].append(end_token)\n",
    "                else:                                                   # If the answer tokens were NOT found, add a default value of 0\n",
    "                    tokenized_examples[\"start_positions\"].append(0)\n",
    "                    tokenized_examples[\"end_positions\"].append(0)\n",
    "            else:     # If there is no TEXT for answer, add a default value of 0\n",
    "                tokenized_examples[\"start_positions\"].append(0)\n",
    "                tokenized_examples[\"end_positions\"].append(0)\n",
    "        else: # If there is no POSITION for the example's answer, add a default value of 0\n",
    "            tokenized_examples[\"start_positions\"].append(0)\n",
    "            tokenized_examples[\"end_positions\"].append(0)\n",
    "\n",
    "    return tokenized_examples\n",
    "\n",
    "\n",
    "# Preprocess the train set\n",
    "train_dataset = dataset[\"train\"].map(preprocess_data, batched=True, remove_columns=dataset[\"train\"].column_names) # Working with big datasets\n",
    "# train_dataset = dataset[\"train\"].shuffle(seed=42).select(range(1000)).map(preprocess_data, batched=True, remove_columns=dataset[\"train\"].column_names) # Working with smaller datasets\n",
    "\n",
    "# Set up DataLoader, handling variable sequence lengths\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, collate_fn=data_collator) # Batch size >8 gives me CUDA out of memory :$\n",
    "\n",
    "# Training parameters\n",
    "epochs = 1\n",
    "learning_rate = 3e-5\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate) # Try Adam, SDG, and lr schedulers\n",
    "\n",
    "# Set device to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "print(\"Start:\",datetime.datetime.now())\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    i = 0\n",
    "    running_loss = 0\n",
    "    for batch in train_loader:\n",
    "        running_loss = 0\n",
    "        # Move batch to device\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        start_positions = batch[\"start_positions\"].to(device)\n",
    "        end_positions = batch[\"end_positions\"].to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, start_positions=start_positions, end_positions=end_positions)\n",
    "        loss = outputs.loss\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # Print execution progress every 100 steps. \n",
    "        \n",
    "        # Track the loss\n",
    "        total_loss += loss.item()\n",
    "        running_loss += loss.item()\n",
    "        i += 1\n",
    "        if i % 100 == 99:    # Imprime la pérdida cada 100 mini-batches\n",
    "            print('[%d, %5d] running_loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 100))\n",
    "    \n",
    "    # Print the average loss for this epoch\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {avg_loss}\")\n",
    "print(\"End:\",datetime.datetime.now())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
